---
title: "Class 7: Clustering and PCA"
author: "Emmanuel R"
format: pdf
---

#CLustering

First let's make up some data to cluster so we can get a feel for these methods and how to work with them.

We can use the `rnorm()` function to get random numbers from a normal distriution around a given `mean`

```{r}
hist( rnorm(500, mean= 3))
```

Let's get 30 points for a mean of 3.

```{r}
tmp <- c(rnorm(30, mean= 3), rnorm(30, mean= -3))
```

```{r}
x <- cbind(x= tmp, y= rev(tmp))
plot(x)
```

## K-means clustering

Very popular clustering method that we can use with the `kmeans()` function in base R.

```{r}
km <- kmeans(x, centers= 2)
km
```


```{r}
# Generate some example data for clustering
tmp1 <- c(rnorm(30,-3), rnorm(30,3))
x <- data.frame(x=tmp1, y=rev(tmp1))

plot(x)

```


# Generate some example data for clustering


```{r}
km$size
```


> Q. Plot x colored by the means 


```{r}
mycols <- c(1, 2)
plot(x, col= km$cluster)
points(km$centers, col= "blue", pch =15, )
```


> Q. Let's cluster into 3 groups or some `x`data and make a plot.

```{r}
km <- kmeans(x, centers= 3)
plot(x, col= km$cluster)
```


# Hierarchial cluster

We can use the `hclust()` function for Hierarchial Clustering. Unlike `kmeans()`, where we could just passin our data as input, we need to give `hclust()` a "distance mark". 


We will use the `dist()` function to start with. 

```{r}
d <- dist(x)
hc <- hclust(d)
hc
```


```{r}
plot(hc)
```

I can now cut my tree to yield a custer membership function with `cutree()`. 


```{r}
cutree(hc, h=8)
```

You can also tell 'cutree()` to cut where it yields "k" groups.

```{r}
grps <- cutree(hc, k= 2)
grps
plot(x, col= grps)
```


# Principal Component Analysis (PCA)

# Start of Lab Part 1
```{r}
url <- "https://tinyurl.com/UK-foods"
x <- read.csv(url, row.names = 1)
x
```
 
> Q1. How many rows and columns are in your new data frame named x? What R functions could you use to answer this questions?

```{r}
dim(x)
```


```{r}
head(x)
```


> Q2. Which approach to solving the ‘row-names problem’ mentioned above do you prefer and why? Is one approach more robust than another under certain circumstances?

I prefer the second method. Much faster and easier.


```{r}
barplot(as.matrix(x), beside=F, col=rainbow(nrow(x)))
```

> Q3: Changing what optional argument in the above barplot() function results in the following plot?

Changing the `beside` argument will give the second plot result.

> Q5: Generating all pairwise plots may help somewhat. Can you make sense of the following code and resulting figure? What does it mean if a given point lies on the diagonal for a given plot?

```{r}
pairs(x, col=rainbow(10), pch=16)
```

> Q6. What is the main differences between N. Ireland and the other countries of the UK in terms of this data-set?



The main PCA function in base R is called `prcomp()` it expects the transpose of our data.

```{r}
pca <- prcomp( t(x) )
summary(pca)
```

```{r}
pca$x
```


> Q7. Complete the code below to generate a plot of PC1 vs PC2. The second line adds text labels over the data points.
> Q8. Customize your plot so that the colors of the country names match the colors in our UK and Ireland map and table at start of this document.

```{r}
plot(pca$x[, 1], pca$x[, 2], col= c("orange", "red", "blue", "darkgreen"), pch= 16)
```

















